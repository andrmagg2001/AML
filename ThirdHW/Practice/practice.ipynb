{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AML Homework 3: Practice\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents:\n",
    "This notebook is composed of 7 Sections for 17 points\n",
    "\n",
    "* **Section 1: Train a CNN from Scratch on CIFAR-10 ( 2 Points)**\n",
    "\n",
    "    We will implement a Convolutional Neural Network (CNN) from the ground up to classify images from the CIFAR-10 dataset. The focus will be on understanding the architecture of CNNs, preprocessing the dataset, and optimizing the model to achieve high accuracy.\n",
    "\n",
    "* **Section 2: Unlearning( 2 Points)**\n",
    "\n",
    "    We introduce the concept of unlearning, which involves modifying a trained model to forget specific data points while retaining its overall performance.\n",
    "\n",
    "* **Section 3: Gold model ( 2 Points)**\n",
    "\n",
    "    We discuss the development of the Gold model, which serves as the benchmark for evaluating performance after implementing unlearning techniques. \n",
    "\n",
    "\n",
    "* **Section 4: Mia Attacks ( 3 Points)**\n",
    "\n",
    "    This section will focus on MIA (Membership Inference Attacks), which are designed to determine whether a specific data point was included in the training set of a machine learning model. \n",
    "    \n",
    "* **Section 5: Unlearning with KL divergence ( 2 Points)**\n",
    "\n",
    "    This section will discuss the application of Kullback-Leibler (KL) divergence in the unlearning process, emphasizing its role in quantifying the difference between the model's original and modified predictions.\n",
    "\n",
    "* **Section 6: GMN for Unlearning ( 6 Points)**\n",
    "\n",
    "    This section will introduce the use of Graph Meta Networks (GMNs) in the unlearning process, highlighting their ability to adaptively modify model parameters based on specific unlearning tasks.\n",
    "\n",
    "Do not modify parts of code that are not marked with \"Your turn\" or \"Add your code below\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "from sklearn import linear_model, model_selection\n",
    "from torch_geometric.data import Data\n",
    "from gmn.graph_construct.model_arch_graph import sequential_to_arch, arch_to_graph\n",
    "import torch.nn.functional as F\n",
    "import platform as pl\n",
    "\n",
    "\n",
    "#fix seeds\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Train from scratch a CNN on CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1: Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    '''\n",
    "    Create a simple CNN model for CIFAR10 dataset\n",
    "    '''\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=(3, 3), stride=1, padding=1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "        nn.Dropout(p=0.1),\n",
    "\n",
    "        nn.Conv2d(32, 64, kernel_size=(3, 3), stride=1, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "        nn.Dropout(p=0.1),\n",
    "\n",
    "        nn.Conv2d(64, 64, kernel_size=(3, 3), stride=1, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.AdaptiveAvgPool2d((1,1)),\n",
    "        nn.Flatten(),\n",
    "        nn.Dropout(p=0.1),\n",
    "        \n",
    "        nn.Linear(64, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.1),\n",
    "        \n",
    "        nn.Linear(32, 10)\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your turn ( 1 Point)\n",
    "\n",
    "Calculate the mean and the standard deviation vectors to be used in cifar_transforms  rounding the values to four decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "Add your code below\n",
    "'''\n",
    "images = np.stack([train_dataset[i][0] for i in range(len(train_dataset))])\n",
    "\n",
    "# Compute the mean and standard deviation for each channel\n",
    "mean = images.mean(axis=(0, 2, 3))\n",
    "std = images.std(axis=(0, 2, 3))\n",
    "\n",
    "print(\"Mean: \", np.round(mean, 4))\n",
    "print(\"Std: \", np.round(std, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the augmentations for the training set\n",
    "cifar_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),                    # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean, std),          # Normalize the image channel\n",
    "])\n",
    "\n",
    "# Load the CIFAR-10 dataset with the appropriate transforms\n",
    "train_dataset = datasets.CIFAR10(root=\"data\", train=True, transform=cifar_transforms, download=True)  \n",
    "test_dataset = datasets.CIFAR10(root=\"data\", train=False, transform=cifar_transforms, download=True)  \n",
    "\n",
    "#split test into test and validation\n",
    "val_dataset, test_dataset = torch.utils.data.random_split(test_dataset, [2000, 8000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "# Create the DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 See the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 2 figures for each of the 10 classes in the dataset\n",
    "fig, axs = plt.subplots(2, 10, figsize=(20, 4))\n",
    "for i in range(10):\n",
    "    # Get the first image of each class\n",
    "    img = train_dataset.data[train_dataset.targets.index(i)]\n",
    "    axs[0, i].imshow(img)\n",
    "    axs[0, i].axis('off')\n",
    "    axs[0, i].set_title(train_dataset.classes[i])\n",
    "\n",
    "    # Get the second image of each class\n",
    "    img = train_dataset.data[train_dataset.targets.index(i, train_dataset.targets.index(i) + 1)]\n",
    "    axs[1, i].imshow(img)\n",
    "    axs[1, i].axis('off')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We had to add this check cause we are also using ARM systems\n",
    "if pl.system() == \"Darwin\":\n",
    "    device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#load weights\n",
    "model = create_model()\n",
    "model.load_state_dict(torch.load('checkpoint/model_weights.pth', weights_only=True))  \n",
    "model.to(device)\n",
    "\n",
    "# initialize the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "num_epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for storing losses for each epoch\n",
    "losses = []\n",
    "losses_val = []\n",
    "\n",
    "# Training the model\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    ######### TRAINING ##########\n",
    "    model.train()\n",
    "    running_loss = 0  # To track loss for this epoch\n",
    "\n",
    "    # Using tqdm for the progress bar\n",
    "    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=True)\n",
    "    \n",
    "    for batch_idx, (data, targets) in loop:\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # Forward pass\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Update progress bar with loss and epoch information\n",
    "        loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "\n",
    "    #scheduler \n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "    # Print loss for this epoch\n",
    "    tqdm.write(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    ####### VALIDATION ########\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in val_loader:\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "\n",
    "            scores = model(data)\n",
    "            loss = criterion(scores, targets)\n",
    "            val_loss += loss.item()\n",
    "        # Calculate average loss for the epoch\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        losses_val.append(avg_val_loss)\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "        # if avg val_loss is better than the one before, save the model\n",
    "        if epoch == 0:\n",
    "            # create directory if not exist\n",
    "            os.makedirs(\"checkpoint\", exist_ok=True)\n",
    "            best_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), \"checkpoint/trained_model.pth\")\n",
    "        elif avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), \"checkpoint/trained_model.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the losses after training\n",
    "# epoch of best validation loss \n",
    "print(f\"Best validation loss: {best_loss:.4f}\")\n",
    "index_best = losses_val.index(best_loss)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(range(1,num_epochs+1), losses, label=\"Train Loss\")\n",
    "plt.plot(range(1,num_epochs+1), losses_val, label=\"Val Loss\")\n",
    "plt.axvline(index_best+1, color='r', linestyle='--', label=\"Best Val Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss vs Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Turn (1 point)\n",
    "\n",
    "**Question**\n",
    "\n",
    "Q: *Based on what you've learned in the lectures and by examining the image above, identify the problems with this plot and explain how to fix them.*\n",
    "\n",
    "A: it can be seen that:\n",
    "\n",
    "1) *Loss oversizing* :  \"Val Loss\" oscillates and reach the minimum Loss at the 18 epoch. This could indicate that the model is starting to overfit to the training data, adapting too much to the specifich characteristics of the training set and losing its ability to generalize well on new data.\n",
    "\n",
    "2) *Stability of Val Loss* : There is no constant variability in the Val Loss curve, that could mean:\n",
    "\n",
    "    - The Branch Size is too small, that put high variance in the loss estimates. Increasing the batch size could stabilize the Val Loss curve\n",
    "\n",
    "    - There a possibile noise inside the dataset\n",
    "\n",
    "3) *Difference between train and Val Loss* : While the Train Loss has a constant decrease, the other (Val Loss) fluctuates. The Training and Val Loss should converge, but there's an increasing discrepancy.\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Evaluation\n",
    "\n",
    "Now, let's evaluate the performances of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy \n",
    "def accuracy (model, loader):\n",
    "    '''\n",
    "    Function to calculate the accuracy of the model on the test set\n",
    "    '''\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, targets in loader:\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "        scores = model(data)\n",
    "        _, predictions = scores.max(1)\n",
    "        correct += (predictions == targets).sum()\n",
    "        total += targets.shape[0]\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your model \n",
    "model = create_model()\n",
    "model.load_state_dict(torch.load('checkpoint/trained_model.pth', weights_only=True))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Calculate accuracy on the train and test set \n",
    "train_accuracy = accuracy(model, train_loader)\n",
    "test_accuracy = accuracy(model, test_loader)\n",
    "\n",
    "print(f\"Your Model Train Accuracy : {100* train_accuracy:.4f}\")\n",
    "print(f\"Your Model Test Accuracy : {100* test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid training for too many epochs, here it is a checkpoint you can use for the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.load_state_dict(torch.load(\"checkpoint/best_model.pth\",map_location=\"mps\", weights_only=False))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Calculate the accuracy on the train and test set\n",
    "train_accuracy = accuracy(model, train_loader)\n",
    "test_accuracy = accuracy(model, test_loader)\n",
    "\n",
    "print(f\"Train accuracy: {100* train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {100* test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Unlearning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of machine learning, unlearning refers to the process of modifying a trained model so that it forgets specific pieces of information without losing the general performance. This is particularly important in situations where data privacy is a concern, such as when sensitive information is involved, or when a model has learned from outdated or incorrect data. In this scenario, \n",
    "you may want to unlearn an entire class of data, a specific instance within that class, or even a particular concept that the model has learned. \n",
    "\n",
    "**Why is Unlearning Important?**\n",
    "\n",
    "Let’s say you have trained a machine learning model to recognize different types of animals based on a dataset containing images. Now, suppose that this dataset includes images of a particular cat breed that was later found to be misclassified or problematic. You might need to remove that specific information from the model to ensure it doesn't make incorrect predictions in the future.\n",
    "\n",
    "Additionally, with privacy laws like GDPR (General Data Protection Regulation), individuals have the right to request that their personal data be removed from a model. If a model has been trained on this data, we need a way to unlearn it.\n",
    "\n",
    "Here, our task will be to unlearn the class of Airplanes in CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unlearning by Fine-Tuning \n",
    "\n",
    "The Unlearning by Fine-Tuning strategy is a technique used to remove the influence of specific data points from a trained machine learning model while preserving its performance on other, relevant data. \n",
    "Here’s a detailed explanation of how this strategy works:\n",
    "\n",
    "#### 1. The Retain Set\n",
    "\n",
    "The retain set consists of all the data points that you want the model to remember or continue to learn from. This set excludes the data points you want the model to forget.\n",
    "\n",
    "####  2. Fine-Tuning Process\n",
    "\n",
    "To perform unlearning through this strategy, you follow these steps:\n",
    "\n",
    "- Identify and Remove the Data Points: First, identify the data points that you wish to unlearn and remove them from the training dataset.\n",
    "\n",
    "- Prepare the Retain and Forget Set: Create a new training dataset that contains only the retain set, those data points that should be kept in the model’s knowledge, and include the remaing data in the Forget Set.\n",
    "\n",
    "- Fine-Tuning on the Retain Set: Instead of retraining the model from scratch, you will fine-tune the existing model using the retain set. This involves using the retain set to continue training the model, typically with a lower learning rate to ensure that the model can adjust its parameters without drastically altering what it has already learned.\n",
    "\n",
    "#### 3. Benefits of this strategy\n",
    "\n",
    "- Efficiency: Fine-tuning on the retain set only is more efficient than retraining the model from scratch. It saves computational resources and time.\n",
    "\n",
    "- Maintained Performance: The model retains its ability to perform well on the general dataset, as it continues to learn from the valid data in the retain set.\n",
    "\n",
    "#### 4. Drawbacks of this strategy\n",
    "\n",
    "- Even if more efficient than retraining the model from scratch, you still need to do a fine tuning, that could be very expensive for large or foundational models. Even finding the best hyperparameters can be costly.\n",
    "\n",
    "- If you change samples or architecture to unlearn, you have to do the ad-hoc fine tuning again, it is not a *general* strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: Forget Airplanes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Turn ( 1 Point)\n",
    "\n",
    "Generate the retain and forget datasets, keeping in mind that we want to forget the \"airplanes\" class. Afterward, create new instances of the loaders for training, validation, and testing. Make sure to use the torch.utils.data.Subset function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "'''\n",
    "Add your code below\n",
    "'''\n",
    "# Airplanes correspond to class_id = 0\n",
    "class_id = 0\n",
    "\n",
    "# extract all labels\n",
    "labels = np.array([label for _, label in train_dataset])\n",
    "\n",
    "# get index where airplanes are present\n",
    "indices_to_forget = np.where(labels == class_id)[0]\n",
    "indices_to_remember = np.where(labels != class_id)[0]\n",
    "\n",
    "retain_dataset = torch.utils.data.Subset(train_dataset, indices_to_remember)\n",
    "forget_dataset = torch.utils.data.Subset(train_dataset, indices_to_forget)\n",
    "retain_loader = DataLoader(retain_dataset, batch_size)\n",
    "forget_loader = DataLoader(forget_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation\n",
    "'''\n",
    "Add your code below\n",
    "'''\n",
    "# Airplanes correspond to class_id = 0\n",
    "class_id = 0\n",
    "\n",
    "# extract all labels\n",
    "labels = np.array([label for _, label in val_dataset])\n",
    "\n",
    "# get index where airplanes are present\n",
    "indices_to_forget = np.where(labels == class_id)[0]\n",
    "indices_to_remember = np.where(labels != class_id)[0]\n",
    "\n",
    "retain_dataset_val = torch.utils.data.Subset(val_dataset, indices_to_remember)\n",
    "forget_dataset_val = torch.utils.data.Subset(val_dataset, indices_to_forget)\n",
    "retain_loader_val = DataLoader(retain_dataset_val, batch_size)\n",
    "forget_loader_val = DataLoader(forget_dataset_val, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test \n",
    "'''\n",
    "Add your code below\n",
    "'''\n",
    "# Airplanes correspond to class_id = 0\n",
    "class_id = 0\n",
    "\n",
    "# extract all labels\n",
    "labels = np.array([label for _, label in test_dataset])\n",
    "\n",
    "# get index where airplanes are present\n",
    "indices_to_forget = np.where(labels == class_id)[0]\n",
    "indices_to_remember = np.where(labels != class_id)[0]\n",
    "\n",
    "retain_dataset_test = torch.utils.data.Subset(test_dataset, indices_to_remember)\n",
    "forget_dataset_test = torch.utils.data.Subset(test_dataset, indices_to_forget)\n",
    "retain_loader_test = DataLoader(retain_dataset_test, batch_size)\n",
    "forget_loader_test = DataLoader(forget_dataset_test, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2: Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unlearning( model, retain_loader , validation, epochs = 5, criterion = criterion, optimizer = optimizer, scheduler = scheduler):\n",
    "    \"\"\"Unlearning by fine-tuning.\n",
    "\n",
    "    Fine-tuning is a very simple algorithm that trains using only\n",
    "    the retain set.\n",
    "\n",
    "    Args:\n",
    "      model : nn.Module.\n",
    "        pre-trained model to use as base of unlearning.\n",
    "      retain : torch.utils.data.DataLoader.\n",
    "        Dataset loader for access to the retain set. This is the subset\n",
    "        of the training set that we don't want to forget.\n",
    "      validation : torch.utils.data.DataLoader.\n",
    "        Dataset loader for access to the validation set. This method doesn't\n",
    "        make use of the validation set.\n",
    "    Returns:\n",
    "      model : updated model\n",
    "    \"\"\"\n",
    "    # We had to add this check cause we are also using ARM systems\n",
    "    if pl.system() == \"Darwin\":\n",
    "      device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "    else:\n",
    "      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    losses = []\n",
    "    losses_val = []\n",
    "   \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        loss_epoch = 0\n",
    "        loop = tqdm(enumerate(retain_loader), total=len(retain_loader), leave=True)\n",
    "        for batch_idx, (inputs, targets) in loop:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #running loss\n",
    "            loss_epoch += loss.item()\n",
    "            # Update progress bar with loss and epoch information\n",
    "            loop.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        #avg loss\n",
    "        avg_loss = loss_epoch / len(retain_loader )\n",
    "        losses.append(avg_loss)\n",
    "        #scheduler step\n",
    "        scheduler.step(avg_loss)\n",
    "        tqdm.write(f\"Epoch [{epoch+1}/{epochs}], Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # validation\n",
    "        loss_val = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, targets in retain_loader_val:\n",
    "                data = data.to(device=device)\n",
    "                targets = targets.to(device=device)\n",
    "\n",
    "                scores = model(data)\n",
    "                loss = criterion(scores, targets)\n",
    "                loss_val += loss.item()\n",
    "            # Calculate average loss for the epoch\n",
    "            avg_val_loss = loss_val / len(validation)\n",
    "            losses_val.append(avg_val_loss)\n",
    "            print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "            # if avg val_loss is better than the one before, save the model\n",
    "            if epoch == 0:\n",
    "                # create directory if not exist\n",
    "                os.makedirs(\"checkpoint\", exist_ok=True)\n",
    "                best_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), \"checkpoint/forget_model.pth\")\n",
    "            elif avg_val_loss < best_loss:\n",
    "                best_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), \"checkpoint/forget_model.pth\")\n",
    "        \n",
    "                \n",
    "    model.eval()\n",
    "    model.load_state_dict(torch.load(\"checkpoint/forget_model.pth\"))\n",
    "    return model, losses, losses_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize forget model as trained model\n",
    "forget_model = create_model()\n",
    "forget_model.load_state_dict(torch.load(\"checkpoint/best_model.pth\", map_location=\"cpu\", weights_only=False))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(forget_model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "\n",
    "# Unlearn the forget set\n",
    "epochs = 10\n",
    "forget_model, losses, losses_val = unlearning(forget_model, retain_loader, val_loader, epochs=epochs, criterion=criterion, optimizer=optimizer, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below there is the evaluation of your unlearned by fine-tuning model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load weights forget model\n",
    "forget_model = create_model()\n",
    "forget_model.load_state_dict(torch.load(\"checkpoint/forget_model.pth\"))\n",
    "forget_model.eval()\n",
    "forget_model.to(device)\n",
    "\n",
    "# print accuracies on retain, forget and test set\n",
    "retain_accuracy = accuracy(forget_model, retain_loader)\n",
    "forget_accuracy = accuracy(forget_model, forget_loader)\n",
    "test_accuracy = accuracy(forget_model, test_loader)\n",
    "test_accuracy_retain = accuracy(forget_model, retain_loader_test)\n",
    "test_accuracy_forget = accuracy(forget_model, forget_loader_test)\n",
    "\n",
    "print(f\"Retain set Accuracy: {100* retain_accuracy:.4f}\")\n",
    "print(f\"Forget set Accuracy: {100* forget_accuracy:.4f}\")\n",
    "print(f\"Test set Accuracy: {100* test_accuracy:.4f}\") # whole test set\n",
    "print(f\"Test set Retain Accuracy: {100* test_accuracy_retain:.4f}\")\n",
    "print(f\"Test set Forget Accuracy: {100* test_accuracy_forget:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Turn (1 Point)\n",
    "\n",
    "**Question**\n",
    "\n",
    "Q: *Summarize what you have learned. Specifically, interpret the accuracy values for the retain and forget sets during training. Additionally, discuss what can be inferred from the accuracy at test time for the entire test set, as well as for the two subsets of forget and retain.*\n",
    "\n",
    "A: \n",
    "The high accuracy on the retain set indicates that the model has preserved a good generalization ability on the data we are not trying to forget.\n",
    "The relatively low accuracy on the forget set during training suggests that the unlearning process is working to some extent: the model has significantly reduced its ability to correctly predict the data we are trying to forget.\n",
    "The accuracy on the test set indicates that the model is performing well despite unlearning the forget set. This shows that the process of forgetting certain data has not significantly degraded the model’s performance on the remaining data.\n",
    "The model’s accuracy on the test set retain indicates that the model has successfully retained knowledge of the data we do not want it to forget. This means that the unlearning process has been effective in forgetting only the relevant data without significantly compromising the model's ability to generalize on the retained data.\n",
    "The low accuracy on the test set forget is a positive sign for the unlearning process. Such a low accuracy suggests that the model has successfully forgotten most of the information related to the forget set, as it can no longer correctly classify those examples. This indicates that unlearning has been effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Gold model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One might ask, how good are the scores above? What is the best possible score? Since our goal is to approximate a model that has been trained **only on** the retain set, we'll consider that the gold standard is the score achieved by this model. Such a model is called here the *gold model*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We had to add this check cause we are also using ARM systems\n",
    "if pl.system() == \"Darwin\":\n",
    "    device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# train only on retain set\n",
    "gold_model = create_model()\n",
    "gold_model.load_state_dict(torch.load(\"checkpoint/model_weights.pth\"))\n",
    "gold_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(gold_model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Turn ( 1 Point)\n",
    "\n",
    "Implement the training loop for the Gold Model. Store you losses inside the ```losses``` and ```losses_val``` lists.\n",
    "\n",
    "**IMPORTANT: save the best checkpoint of this model to a checkpoint file called \"checkpoint/gold_model.pth\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Variabile per il miglior validation loss\n",
    "best_loss = float('inf')\n",
    "\n",
    "losses = []\n",
    "losses_val = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    gold_model.train()\n",
    "    running_loss = 0\n",
    "    \n",
    "    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=True)\n",
    "\n",
    "    for batch_idx, (data, targets) in loop:\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # Forward pass\n",
    "        scores = gold_model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Update progress bar\n",
    "        loop.set_description(f\"\\033[34mEpoch [{epoch+1}/{num_epochs}]\\033[0m\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "\n",
    "    scheduler.step(avg_loss)\n",
    "    print(f\"Training loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    gold_model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in val_loader:\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "\n",
    "            scores = gold_model(data)\n",
    "            loss = criterion(scores, targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    losses_val.append(avg_val_loss)\n",
    "\n",
    "    # Save best model based on validation loss\n",
    "    if avg_val_loss < best_loss:\n",
    "        best_loss = avg_val_loss\n",
    "        os.makedirs(\"checkpoint\", exist_ok=True)\n",
    "        torch.save(gold_model.state_dict(), \"checkpoint/gold_model.pth\")\n",
    "        print(\"\\033[92mBest model saved with validation loss: {:.4f}\\033[0m\".format(best_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the losses after training\n",
    "# epoch of best validation loss \n",
    "print(f\"Best validation loss: {best_loss:.4f}\")\n",
    "index_best = losses_val.index(best_loss)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(range(1,num_epochs+1), losses, label=\"Train Loss\")\n",
    "plt.plot(range(1,num_epochs+1), losses_val, label=\"Val Loss\")\n",
    "plt.axvline(index_best+1, color='r', linestyle='--', label=\"Best Val Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss vs Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below there is the evaluation of the gold model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights gold model\n",
    "gold_model = create_model()\n",
    "gold_model.load_state_dict(torch.load(\"checkpoint/gold_model.pth\"))\n",
    "gold_model.eval()\n",
    "gold_model.to(device)\n",
    "\n",
    "# print accuracies on retain, forget and test set\n",
    "retain_accuracy = accuracy(gold_model, retain_loader)\n",
    "forget_accuracy = accuracy(gold_model, forget_loader)\n",
    "test_accuracy = accuracy(gold_model, test_loader)\n",
    "test_accuracy_retain = accuracy(gold_model, retain_loader_test)\n",
    "test_accuracy_forget = accuracy(gold_model, forget_loader_test)\n",
    "\n",
    "print(f\"Retain set Accuracy: {100* retain_accuracy:.4f}\")\n",
    "print(f\"Forget set Accuracy: {100* forget_accuracy:.4f}\")\n",
    "print(f\"Test set Accuracy: {100* test_accuracy:.4f}\")\n",
    "print(f\"Test set Retain Accuracy: {100* test_accuracy_retain:.4f}\")\n",
    "print(f\"Test set Forget Accuracy: {100* test_accuracy_forget:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Turn\n",
    "\n",
    "**Question**\n",
    "\n",
    "Q: *Explain the results of the Gold Model. Did you notice something strange?*\n",
    "\n",
    "A: The Gold Model shows a constant improvement, with a less loss during the training and saving a checkpoint when it reaches its best perfomance.\n",
    "After the checkpoint load, the model has an greater accuracy  on *retain* set than *forget*. This difference is expected, as the model is designed to keep the important information of the\n",
    "*retain* set and selectively disregard that of the *forget* one.\n",
    "In this way, it shows that it can effectively differentiate between the two types of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Mia attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll quantify the quality of the unlearning algorithm through a simple membership inference attack (MIA).\n",
    "MIAs are a type of adversarial attack aimed at determining whether a specific data point was included in the training dataset of a machine learning model. These attacks exploit the behavior of the model to make inferences about the presence or absence of certain data points.\n",
    "This MIA consists of a logistic regression model that predicts whether the model was trained on a particular sample from that sample's loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_losses(model, loader, criterion = \"CrossEntropy\"):\n",
    "\n",
    "    \"\"\"\n",
    "    Auxiliary function to compute per-sample losses\n",
    "    Args:\n",
    "    model : model to evaluate\n",
    "    loader : data loader\n",
    "    criterion : loss function. Specify \"CrossEntropy\" for cross-entropy loss or \"KL\" for KL divergence\n",
    "    \"\"\"\n",
    "    # We had to add this check cause we are also using ARM systems\n",
    "    if pl.system() == \"Darwin\":\n",
    "        device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "    else:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    all_losses = []\n",
    "\n",
    "    for inputs, targets in loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        logits = model(inputs)\n",
    "        losses = nn.CrossEntropyLoss(reduction = \"none\")(logits, targets).detach().cpu().numpy()\n",
    "   \n",
    "        for l in losses:\n",
    "            all_losses.append(l)\n",
    "\n",
    "    return np.array(all_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "model = create_model()\n",
    "model.load_state_dict(torch.load(\"checkpoint/best_model.pth\",map_location=\"mps\"));\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "retain_losses = compute_losses(model, retain_loader_test)\n",
    "forget_losses = compute_losses(model, forget_loader_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forget model\n",
    "forget_model = create_model()\n",
    "forget_model.load_state_dict(torch.load(\"checkpoint/forget_model.pth\"));\n",
    "forget_model.eval()\n",
    "forget_model.to(device)\n",
    "\n",
    "retain_losses_forget = compute_losses(forget_model, retain_loader_test)\n",
    "forget_losses_forget = compute_losses(forget_model, forget_loader_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold model\n",
    "gold_model = create_model()\n",
    "gold_model.load_state_dict(torch.load(\"checkpoint/gold_model.pth\"));\n",
    "gold_model.eval()\n",
    "gold_model.to(device)\n",
    "\n",
    "retain_losses_gold = compute_losses(gold_model, retain_loader_test)\n",
    "forget_losses_gold = compute_losses(gold_model, forget_loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 plots woth ax of histograms\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "#subsample retrain losses to have the same size as the forget losses\n",
    "random_idx = np.random.choice(np.arange(len(retain_losses)), len(forget_losses), replace=False)\n",
    "retain_losses = retain_losses[random_idx]\n",
    "retain_losses_forget = retain_losses_forget[random_idx]\n",
    "retain_losses_gold = retain_losses_gold[random_idx]\n",
    "\n",
    "\n",
    "axs[0].hist(retain_losses, density = True, bins=50, alpha=0.5, label='Retain', color='blue')\n",
    "axs[0].hist(forget_losses, density = True, bins=50, alpha=0.5, label='Forget', color='red')\n",
    "axs[0].set_title('Model')\n",
    "axs[0].set_xlabel('Loss')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].hist(retain_losses_forget, density = True, bins=50, alpha=0.5, label='Retain', color='blue')\n",
    "axs[1].hist(forget_losses_forget, density = True, bins=50, alpha=0.5, label='Forget', color='red')\n",
    "axs[1].set_title('Forget Model')\n",
    "axs[1].set_xlabel('Loss')\n",
    "axs[1].legend()\n",
    "\n",
    "axs[2].hist(retain_losses_gold, density = True, bins=50, alpha=0.5, label='Retain', color='blue')\n",
    "axs[2].hist(forget_losses_gold, density = True, bins=50, alpha=0.5, label='Forget', color='red')\n",
    "axs[2].set_title('Gold Model')\n",
    "axs[2].set_xlabel('Loss')\n",
    "axs[2].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_mia(sample_loss, members, n_splits=10, random_state=0):\n",
    "    \"\"\"Computes cross-validation score of a membership inference attack.\n",
    "\n",
    "    Args:\n",
    "      sample_loss : array_like of shape (n,).\n",
    "        objective function evaluated on n samples.\n",
    "      members : array_like of shape (n,),\n",
    "        whether a sample was used for training.\n",
    "      n_splits: int\n",
    "        number of splits to use in the cross-validation.\n",
    "    Returns:\n",
    "      scores : array_like of size (n_splits,)\n",
    "    \"\"\"\n",
    "    \n",
    "    torch.manual_seed(torch.initial_seed())\n",
    "    \n",
    "    unique_members = np.unique(members)\n",
    "    if not np.all(unique_members == np.array([0, 1])):\n",
    "        raise ValueError(\"members should only have 0 and 1s\")\n",
    "\n",
    "    attack_model = linear_model.LogisticRegression(random_state=random_state)\n",
    "    cv = model_selection.StratifiedShuffleSplit(\n",
    "        n_splits=n_splits, random_state = 0\n",
    "    )\n",
    "    \n",
    "    return model_selection.cross_val_score(\n",
    "        attack_model, sample_loss, members, cv=cv, scoring=\"accuracy\", \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mia on model\n",
    "retain_losses_subsample = np.random.choice(retain_losses, len(forget_losses), replace=False)\n",
    "samples_mia = np.concatenate([retain_losses_subsample, forget_losses]).reshape(-1, 1)\n",
    "#balance the number of samples\n",
    "members_mia = np.concatenate([np.zeros(len(retain_losses_subsample)), np.ones(len(forget_losses))])\n",
    "\n",
    "scores_model = simple_mia(samples_mia, members_mia)\n",
    "print(f\"Model MIA score: {scores_model.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mia on forget model\n",
    "retain_losses_forget_subsample = np.random.choice(retain_losses_forget, len(forget_losses_forget), replace=False)\n",
    "samples_mia = np.concatenate([retain_losses_forget_subsample, forget_losses_forget]).reshape(-1, 1)\n",
    "members_mia = np.concatenate([np.zeros(len(retain_losses_forget_subsample)), np.ones(len(forget_losses_forget))])\n",
    "\n",
    "scores_forget = simple_mia(samples_mia, members_mia)\n",
    "print(f\"Forget Model MIA score: {scores_forget.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mia on gold model\n",
    "retain_losses_gold_subsample = np.random.choice(retain_losses_gold, len(forget_losses_gold), replace=False)\n",
    "samples_mia = np.concatenate([retain_losses_gold_subsample, forget_losses_gold]).reshape(-1, 1)\n",
    "members_mia = np.concatenate([np.zeros(len(retain_losses_gold_subsample)), np.ones(len(forget_losses_gold))])\n",
    "\n",
    "scores_gold = simple_mia(samples_mia, members_mia)\n",
    "print(f\"Gold Model MIA score: {scores_gold.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Turn ( 3 Points)\n",
    "\n",
    "**Question**\n",
    "\n",
    "Q: *For each model, analyze the loss plots and explain the results obtained from the membership inference attack (MIA).*\n",
    "\n",
    "A: \n",
    "- **Model**:\n",
    "The loss distributions between the *Retain* and *Forget* samples are very similar, in the plots. \n",
    "That can be considered in a low MIA score, indicating that the model does not expose much information about whether the data was used for training. Therefore, it is difficult for the attacker to discriminate samples on the basis of membership.\n",
    "\n",
    "- **Forget Model**:\n",
    "The loss for the *Forget* samples are higher, andthe loss distributions between *Retain* and *Forget* are well separated.\n",
    "This leads to a higher MIA score, suggesting that this model is vulnerable to MIA attack, as the attacker is bettere able to identify the sample belonging to the training set.\n",
    "\n",
    "- **Gold Model**:\n",
    "Losses are balanced between the *Retain* and *Forget* samples. This model has low MIA score, indicating that it is well generalised and withstands the MIA attack, thus protecting the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Unlearning with Kl divergence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kullback-Leibler (KL) divergence is a measure of how one probability distribution differs from another. In this case, to induce unlearning, we want the model's predictions on the forget set to match a uniform distribution, meaning the model \"forgets\" any specific information about these classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Turn (1 Point) \n",
    "\n",
    "Next, consider a simple scenario to clarify the concept: a classification problem with four classes. Here, the objective is to unlearn one class by enforcing the logits' distribution (after the softmax) to match a uniform distribution. In this case, let the target distribution for a sample coming from the forget set be $y_{gt} = [0.25, 0.25, 0.25, 0.25]$, and assume that you have achieved the predicted distribution $y_{pred} = [0.25, 0.25, 0.25, 0.25]$\n",
    "\n",
    "**Question**\n",
    "\n",
    "Q: *In this context, why is it preferable to use KL divergence instead of Cross-Entropy? Explain it and fill the code below in order to show it numerically.*\n",
    "\n",
    "A: In this case, KL divergence is preferred over Cross-Entropy because it measures how much the predicted distribution deviates from the target (uniform) distribution. Since we want the model to forget by making its predictions match a uniform distribution, KL divergence directly quantifies the distance from this ideal distribution, while Cross-Entropy assumes a specific ground-truth class, which is not applicable here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_gt = torch.tensor([0.25, 0.25, 0.25, 0.25])  \n",
    "y_pred = torch.tensor([0.25, 0.25, 0.25, 0.25])\n",
    "\n",
    "'''\n",
    "Add your code below\n",
    "'''\n",
    "cross_entropy = F.cross_entropy(y_pred.unsqueeze(0), y_gt.argmax().unsqueeze(0))\n",
    "kl_div = F.kl_div(y_pred.log(), y_gt, reduction=\"sum\")\n",
    "\n",
    "print(f\"Cross Entropy: {cross_entropy:.4f}\")\n",
    "print(f\"KL Divergence: {kl_div:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "Q: *Before proceeding, you should explain the relationship between Cross-Entropy and Kullback-Leibler (KL) divergence. Provide the proof showing how to derive the relationship between the two.*\n",
    "\n",
    "A: \n",
    "\n",
    "**Cross-Entropy** measures the difference between two probability distributions for a given set of events outcomes. For two distributions (**P**) (true distribution) and (**Q**) (approx distribution), the cross-entropy is defined as:\n",
    "\n",
    "$$ H(P, Q) = - \\sum_x P(x) \\log Q(x) $$\n",
    "\n",
    "\n",
    "**Kullback-Leibler (KL)** Divergence, measures how one probability distribution diverges from a second, expected probability distribution. For distribution (**P**) and (**Q**), the KL is:\n",
    "\n",
    "$$ D_{KL}(P \\| Q) = \\sum_x P(x) \\log \\frac{P(x)}{Q(x)} $$\n",
    "\n",
    "\n",
    "\n",
    "**Relationship between Cross-Entropy and KL Divergence** can be derived as follows:\n",
    "\n",
    "1. Start with the definition of KL Divergence and rewrite the logarithm term:\n",
    "\n",
    "   $$ D_{KL}(P \\| Q) = \\sum_x P(x) \\log P(x) - \\sum_x P(x) \\log Q(x) $$\n",
    "\n",
    "2. Recognize that the first term is the negative entropy of (**P**):\n",
    "\n",
    "   $$ H(P) = - \\sum_x P(x) \\log P(x) $$\n",
    "\n",
    "   Therefore,\n",
    "\n",
    "   $$ -H(P) = \\sum_x P(x) \\log P(x) $$\n",
    "\n",
    "3. Substitute this into the KL Divergence equation:\n",
    "\n",
    "   $$ D_{KL}(P \\| Q) = -H(P) + \\sum_x P(x) \\log Q(x) $$\n",
    "\n",
    "4. Notice that the second term is the negative cross-entropy:\n",
    "\n",
    "   $$ H(P, Q) = - \\sum_x P(x) \\log Q(x) $$\n",
    "\n",
    "   Therefore\n",
    "\n",
    "   $$ -H(P, Q) = \\sum_x P(x) \\log Q(x) $$\n",
    "\n",
    "5. Combine these results:\n",
    "\n",
    "   $$ D_{KL}(P \\| Q) = -H(P) - H(P, Q) $$\n",
    "\n",
    "   Rearranging gives us:\n",
    "\n",
    "   $$ H(P, Q) = H(P) + D_{KL}(P \\| Q) $$\n",
    "\n",
    "The cross-entropy (**H(P, Q)**) between two distributions (**P**) and (**Q**) is equal to the entropy (**H(P)**) of the true distribution plus the KL divergence (D_{KL}**(P | Q)**) between the true distribution and the approximate distribution. This relationship shows that cross-entropy includes both the inherent uncertainty in the true distribution and the additional uncertainty due to the approximation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix seeds\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target (target, number_of_classes = 10):\n",
    "    '''\n",
    "    Function to modify the target class\n",
    "    '''\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    tensor = torch.nn.functional.one_hot(target, num_classes= number_of_classes ).float().to(device)\n",
    "    # Identify rows with 1 in the first position\n",
    "    first_pos_mask = target == 0\n",
    "    \n",
    "    # Substite the rows with 1 in the first position with a uniform distribution\n",
    "    n = tensor.size(1)  # Numero di colonne\n",
    "    uniform_distribution = torch.full((n,), 1.0 / n, device = device)  # Distribuzione uniforme\n",
    "    tensor[first_pos_mask] = uniform_distribution\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unlearning_2 (model, forget_loader, validation, epochs, optimizer, scheduler):\n",
    "    '''\n",
    "    Function to unlearn the forget set\n",
    "    '''\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    epsilon = 1e-5\n",
    "    model.to(device)\n",
    "    losses = []\n",
    "    losses_val = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        loss_epoch = 0\n",
    "        loop = tqdm(enumerate(forget_loader), total=len(forget_loader), leave=True)\n",
    "        for batch_idx, (inputs, targets) in loop:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs + epsilon\n",
    "            outputs = F.log_softmax(outputs, dim=1)\n",
    "            \n",
    "            targets = make_target(targets)\n",
    "            loss = F.kl_div(outputs, targets, reduction='batchmean')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #running loss\n",
    "            loss_epoch += loss.item()\n",
    "            # Update progress bar with loss and epoch information\n",
    "            loop.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        #avg loss\n",
    "        avg_loss = loss_epoch / len(forget_loader )\n",
    "        losses.append(avg_loss)\n",
    "        #scheduler step\n",
    "        scheduler.step(avg_loss)\n",
    "        tqdm.write(f\"Epoch [{epoch+1}/{epochs}], Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # validation\n",
    "        loss_val = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, targets in validation:\n",
    "                data = data.to(device=device)\n",
    "                targets = targets.to(device=device)\n",
    "\n",
    "                scores = model(data)\n",
    "                scores = scores + epsilon\n",
    "                scores = F.log_softmax(scores, dim=1)\n",
    "                targets = make_target(targets)\n",
    "                loss = F.kl_div(scores, targets, reduction='batchmean')\n",
    "                loss_val += loss.item()\n",
    "            # Calculate average loss for the epoch\n",
    "            avg_val_loss = loss_val / len(validation)\n",
    "            losses_val.append(avg_val_loss)\n",
    "            print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "            # if avg val_loss is better than the one before, save the model\n",
    "            if epoch == 0:\n",
    "                # create directory if not exist\n",
    "                os.makedirs(\"checkpoint\", exist_ok=True)\n",
    "                best_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), \"checkpoint/another_forget_model.pth\")\n",
    "            elif avg_val_loss < best_loss:\n",
    "                best_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), \"checkpoint/another_forget_model.pth\")\n",
    "    return model, losses, losses_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_forget_model = create_model()\n",
    "another_forget_model.load_state_dict(torch.load(\"checkpoint/best_model.pth\", map_location=\"mps\"));\n",
    "another_forget_model.to(device)\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(another_forget_model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "num_epochs = 10\n",
    "\n",
    "forget_loader = forget_loader\n",
    "val_loader = forget_loader_val\n",
    "\n",
    "another_forget_model, losses, losses_val = unlearning_2(another_forget_model, forget_loader, val_loader, num_epochs, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot losses\n",
    "#epoch of best validation loss\n",
    "index_best = losses_val.index(min(losses_val))\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(losses, label=\"Train Loss\")\n",
    "plt.plot(losses_val, label=\"Val Loss\")\n",
    "plt.axvline(index_best, color='r', linestyle='--', label=\"Best Val Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss vs Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy \n",
    "another_forget_model = create_model()\n",
    "another_forget_model.load_state_dict(torch.load(\"checkpoint/another_forget_model.pth\"))\n",
    "another_forget_model.eval()\n",
    "another_forget_model.to(device)\n",
    "\n",
    "\n",
    "# Calculate the accuracy on the test set\n",
    "retain_accuracy = accuracy(another_forget_model, retain_loader)\n",
    "forget_accuracy = accuracy(another_forget_model, forget_loader)\n",
    "test_accuracy = accuracy(another_forget_model, test_loader)\n",
    "retain_test_accuracy = accuracy(another_forget_model, retain_loader_test)\n",
    "forget_test_accuracy = accuracy(another_forget_model, forget_loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print accuracies on retain, forget and test set\n",
    "print(f\"Retain Accuracy: {100* retain_accuracy:.4f}\")\n",
    "print(f\"Forget Accuracy: {100* forget_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {100* test_accuracy:.4f}\")\n",
    "print(f\"Test Retain Accuracy: {100* retain_test_accuracy:.4f}\")\n",
    "print(f\"Test Forget Accuracy: {100* forget_test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate losses of the model on forget and retain test set\n",
    "retain_losses_CE = compute_losses(another_forget_model, retain_loader_test)\n",
    "forget_losses_CE = compute_losses(another_forget_model, forget_loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(retain_losses_CE, density = True, bins=50, alpha=0.5, label='Retain', color='blue')\n",
    "plt.hist(forget_losses_CE, density = True, bins=50, alpha=0.5, label='Forget', color='red')\n",
    "plt.title('Another Forget Model')\n",
    "plt.xlabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mia attack on cross entropy\n",
    "np.random.seed(0)\n",
    "subsample_retain_losses_CE = np.random.choice(retain_losses_CE, len(forget_losses), replace=False)\n",
    "samples_mia = np.concatenate([subsample_retain_losses_CE, forget_losses_CE]).reshape(-1, 1)\n",
    "members_mia = np.concatenate([np.zeros(len(subsample_retain_losses_CE)), np.ones(len(forget_losses))])\n",
    "\n",
    "scores_another_forget = simple_mia(samples_mia, members_mia)\n",
    "print(f\"Another Forget Model MIA score with Cross Entropy losses: {scores_another_forget.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is another way of performing unlearning, you may have noticed that the distributions of the retain and forget sets are different but still there is an overlapping portion. It is very likely that the MIA attack will fail in that specific region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMN for unlearning (6 Points)\n",
    "\n",
    "Now, we will attempt to use the GMN you have implemented in the theory notebook for the unlearning task. Keep in mind that this is a novel and challenging task, and it is quite possible that the results may not meet your expectations. However, this is the nature of research. Therefore, the evaluation will focus on the clarity of your approach and your ability to justify your choices and results, rather then the result itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, go into the ```Practice/gmn/graph_models.py``` file and replace the empty classes with what you have implemented in the second part of the theory notebook. Then, try to think about and implement an unlearning algorithm that leverages the graph metanetwork, and evaluate the unlearned model with MIA attacks and accuracy scores. It would be super cool to have a neural network (the GMN) that can take as input other pretrained neural networks and produce as output the same networks but unlearned over a specific subset of data samples.\n",
    "\n",
    "In the end, generate a detailed report where you describe your idea, methodology and implementation. Put the most of your effort in explaining us the ideas and the intuitions that you had, since this is what we will reward. Don't be worried if results are poor, there can be many causes of this and it's not your task to solve all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our model to graph\n",
    "\n",
    "from gmn.graph_models import *\n",
    "from torch_geometric.data import Data, Batch\n",
    "from gmn.graph_construct.model_arch_graph import sequential_to_arch, arch_to_graph, graph_to_arch, arch_to_sequential\n",
    "from gmn.feature_extractor_gmn import NodeEdgeFeatEncoder\n",
    "from gmn.graph_models import MPNN\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "weights = torch.load(\"checkpoint/best_model.pth\", map_location=\"cpu\")\n",
    "model = create_model()\n",
    "model.load_state_dict(weights)\n",
    "arch = sequential_to_arch(model)\n",
    "x, edge_index, edge_attr = arch_to_graph(arch)\n",
    "x = x.float()\n",
    "edge_attr = edge_attr.float()\n",
    "\n",
    "# currently u is a vector of zeros, and it is basically useless. You can consider filling it with what you prefer and leverage it for the task of unlearning\n",
    "g_cnn = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, u = torch.zeros(1, 8))\n",
    "\n",
    "graph_batch = Batch.from_data_list([g_cnn])\n",
    "print(graph_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMN Dataset Building\n",
    "\n",
    "Now we are gonna create a small CNN, we'll train it and then we will convert it into a graph.\n",
    "\n",
    "For the CNNs we'll use the same structure defined in the first section of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model():\n",
    "    '''\n",
    "    Create a simple CNN model for CIFAR10 dataset\n",
    "    '''\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(3, 32, kernel_size=(3, 3), stride=1, padding=1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.ReLU(),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "        nn.Dropout(p=0.1),\n",
    "\n",
    "        nn.Conv2d(32, 64, kernel_size=(3, 3), stride=1, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "        nn.Dropout(p=0.1),\n",
    "\n",
    "        nn.Conv2d(64, 64, kernel_size=(3, 3), stride=1, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.AdaptiveAvgPool2d((1,1)),\n",
    "        nn.Flatten(),\n",
    "        nn.Dropout(p=0.1),\n",
    "        \n",
    "        nn.Linear(64, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.1),\n",
    "        \n",
    "        nn.Linear(32, 10)\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "Add your code below\n",
    "'''\n",
    "images = np.stack([train_dataset[i][0] for i in range(len(train_dataset))])\n",
    "\n",
    "# Compute the mean and standard deviation for each channel\n",
    "mean = images.mean(axis=(0, 2, 3))\n",
    "std = images.std(axis=(0, 2, 3))\n",
    "\n",
    "print(\"Mean: \", np.round(mean, 4))\n",
    "print(\"Std: \", np.round(std, 4))\n",
    "\n",
    "# Define the augmentations for the training set\n",
    "cifar_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),                    # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean, std),          # Normalize the image channel\n",
    "])\n",
    "\n",
    "# Load the CIFAR-10 dataset with the appropriate transforms\n",
    "train_dataset = datasets.CIFAR10(root=\"data\", train=True, transform=cifar_transforms, download=True)  \n",
    "test_dataset = datasets.CIFAR10(root=\"data\", train=False, transform=cifar_transforms, download=True)  \n",
    "\n",
    "#split test into test and validation\n",
    "val_dataset, test_dataset = torch.utils.data.random_split(test_dataset, [2000, 8000])\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "# Create the DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We had to add this check cause we are also using ARM systems\n",
    "if pl.system() == \"Darwin\":\n",
    "    device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#load weights\n",
    "models = []\n",
    "for _ in range(128):\n",
    "    model = create_model()\n",
    "    model.load_state_dict(torch.load('checkpoint/model_weights.pth', weights_only=True))  \n",
    "    model.to(device)\n",
    "    models.append(model)\n",
    "\n",
    "# initialize the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "count = 0\n",
    "\n",
    "for model in models:\n",
    "    # define random optimizers for training\n",
    "    optimizers = optimizers = [\n",
    "    torch.optim.Adam(model.parameters(), lr=0.001),\n",
    "    torch.optim.Adam(model.parameters(), lr=0.005),\n",
    "    torch.optim.Adam(model.parameters(), lr=0.0001),\n",
    "    torch.optim.SGD(model.parameters(), lr=0.001),\n",
    "    torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "]\n",
    "    \n",
    "    optimizer = random.choice(optimizers)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "    num_epochs = random.randint(1, 4)\n",
    "\n",
    "    # Placeholder for storing losses for each epoch\n",
    "    losses = []\n",
    "    losses_val = []\n",
    "\n",
    "    # Training the model\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        ######### TRAINING ##########\n",
    "        model.train()\n",
    "        running_loss = 0  # To track loss for this epoch\n",
    "\n",
    "        # Using tqdm for the progress bar\n",
    "        loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=True)\n",
    "    \n",
    "        \n",
    "        for batch_idx, (data, targets) in loop:\n",
    "            # Get data to cuda if possible\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "\n",
    "            # Forward pass\n",
    "            scores = model(data)\n",
    "            loss = criterion(scores, targets)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient descent step\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Update progress bar with loss and epoch information\n",
    "            loop.set_description(f\"\\033[34mEpoch [{epoch+1}/{num_epochs}]\\033[0m\")\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        # Calculate average loss for the epoch\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        losses.append(avg_loss)\n",
    "\n",
    "        #scheduler \n",
    "        scheduler.step(avg_loss)\n",
    "\n",
    "        # Print loss for this epoch\n",
    "        tqdm.write(f\"\\033[34mEpoch [{epoch+1}/{num_epochs}]\\033[0m, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        ####### VALIDATION ########\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, targets in val_loader:\n",
    "                data = data.to(device=device)\n",
    "                targets = targets.to(device=device)\n",
    "\n",
    "                scores = model(data)\n",
    "                loss = criterion(scores, targets)\n",
    "                val_loss += loss.item()\n",
    "            # Calculate average loss for the epoch\n",
    "            avg_val_loss = val_loss / len(val_loader)\n",
    "            losses_val.append(avg_val_loss)\n",
    "            print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "            # if avg val_loss is better than the one before, save the model\n",
    "            if epoch == 0:\n",
    "                # create directory if not exist\n",
    "                os.makedirs(\"checkpoint/gmn_dataset\", exist_ok=True)\n",
    "                best_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), \"checkpoint/gmn_dataset/trained_model_\"+str(count)+\".pth\")\n",
    "            elif avg_val_loss < best_loss:\n",
    "                best_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), \"checkpoint/gmn_dataset/trained_model\"+str(count)+\".pth\")\n",
    "    count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application of the normal unlearning we saw in previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "'''\n",
    "Add your code below\n",
    "'''\n",
    "# Airplanes correspond to class_id = 0\n",
    "class_id = 0\n",
    "\n",
    "# extract all labels\n",
    "labels = np.array([label for _, label in train_dataset])\n",
    "\n",
    "# get index where airplanes are present\n",
    "indices_to_forget = np.where(labels == class_id)[0]\n",
    "indices_to_remember = np.where(labels != class_id)[0]\n",
    "\n",
    "retain_dataset = torch.utils.data.Subset(train_dataset, indices_to_remember)\n",
    "forget_dataset = torch.utils.data.Subset(train_dataset, indices_to_forget)\n",
    "retain_loader = DataLoader(retain_dataset, batch_size)\n",
    "forget_loader = DataLoader(forget_dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation\n",
    "'''\n",
    "Add your code below\n",
    "'''\n",
    "# Airplanes correspond to class_id = 0\n",
    "class_id = 0\n",
    "\n",
    "# extract all labels\n",
    "labels = np.array([label for _, label in val_dataset])\n",
    "\n",
    "# get index where airplanes are present\n",
    "indices_to_forget = np.where(labels == class_id)[0]\n",
    "indices_to_remember = np.where(labels != class_id)[0]\n",
    "\n",
    "retain_dataset_val = torch.utils.data.Subset(val_dataset, indices_to_remember)\n",
    "forget_dataset_val = torch.utils.data.Subset(val_dataset, indices_to_forget)\n",
    "retain_loader_val = DataLoader(retain_dataset_val, batch_size)\n",
    "forget_loader_val = DataLoader(forget_dataset_val, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test \n",
    "'''\n",
    "Add your code below\n",
    "'''\n",
    "# Airplanes correspond to class_id = 0\n",
    "class_id = 0\n",
    "\n",
    "# extract all labels\n",
    "labels = np.array([label for _, label in test_dataset])\n",
    "\n",
    "# get index where airplanes are present\n",
    "indices_to_forget = np.where(labels == class_id)[0]\n",
    "indices_to_remember = np.where(labels != class_id)[0]\n",
    "\n",
    "retain_dataset_test = torch.utils.data.Subset(test_dataset, indices_to_remember)\n",
    "forget_dataset_test = torch.utils.data.Subset(test_dataset, indices_to_forget)\n",
    "retain_loader_test = DataLoader(retain_dataset_test, batch_size)\n",
    "forget_loader_test = DataLoader(forget_dataset_test, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are gonna perform unlearning by fine tuning to get targets that our GMN will follow to train its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def unlearning_3(retain_loader , validation, epochs = 5, criterion = criterion, optimizer = optimizer, scheduler = scheduler):\n",
    "    \"\"\"Unlearning by fine-tuning.\n",
    "\n",
    "    Fine-tuning is a very simple algorithm that trains using only\n",
    "    the retain set.\n",
    "\n",
    "    Args:\n",
    "      model : nn.Module.\n",
    "        pre-trained model to use as base of unlearning.\n",
    "      retain : torch.utils.data.DataLoader.\n",
    "        Dataset loader for access to the retain set. This is the subset\n",
    "        of the training set that we don't want to forget.\n",
    "      validation : torch.utils.data.DataLoader.\n",
    "        Dataset loader for access to the validation set. This method doesn't\n",
    "        make use of the validation set.\n",
    "    Returns:\n",
    "      model : updated model\n",
    "    \"\"\"\n",
    "    # We had to add this check cause we are also using ARM systems\n",
    "    if pl.system() == \"Darwin\":\n",
    "      device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "    else:\n",
    "      device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "      \n",
    "    for i in range(len(models)):\n",
    "        \n",
    "        weights = torch.load(\"checkpoint/gmn_dataset/trained_model_\"+str(i)+\".pth\", map_location=\"mps\")\n",
    "        model = create_model()\n",
    "        model.load_state_dict(weights)\n",
    "        model.to(device)\n",
    "\n",
    "        losses = []\n",
    "        losses_val = []\n",
    "        num_epochs = random.randint(1, 4)\n",
    "    \n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            loss_epoch = 0\n",
    "            loop = tqdm(enumerate(retain_loader), total=len(retain_loader), leave=True)\n",
    "            for batch_idx, (inputs, targets) in loop:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                #running loss\n",
    "                loss_epoch += loss.item()\n",
    "                # Update progress bar with loss and epoch information\n",
    "                loop.set_description(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "                loop.set_postfix(loss=loss.item())\n",
    "\n",
    "            #avg loss\n",
    "            avg_loss = loss_epoch / len(retain_loader )\n",
    "            losses.append(avg_loss)\n",
    "            #scheduler step\n",
    "            scheduler.step(avg_loss)\n",
    "            tqdm.write(f\"Epoch [{epoch+1}/{epochs}], Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "            # validation\n",
    "            loss_val = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for data, targets in retain_loader_val:\n",
    "                    data = data.to(device=device)\n",
    "                    targets = targets.to(device=device)\n",
    "\n",
    "                    scores = model(data)\n",
    "                    loss = criterion(scores, targets)\n",
    "                    loss_val += loss.item()\n",
    "                # Calculate average loss for the epoch\n",
    "                avg_val_loss = loss_val / len(validation)\n",
    "                losses_val.append(avg_val_loss)\n",
    "                print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "                # if avg val_loss is better than the one before, save the model\n",
    "                if epoch == 0:\n",
    "                    # create directory if not exist\n",
    "                    os.makedirs(\"checkpoint/gmn_dataset/forget\", exist_ok=True)\n",
    "                    best_loss = avg_val_loss\n",
    "                    torch.save(model.state_dict(), \"checkpoint/gmn_dataset/forget/forget_model_\"+str(i)+\".pth\")\n",
    "                elif avg_val_loss < best_loss:\n",
    "                    best_loss = avg_val_loss\n",
    "                    torch.save(model.state_dict(), \"checkpoint/gmn_dataset/forget/forget_model_\"+str(i)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(forget_model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "unlearning_3(retain_loader=retain_loader, validation=val_loader, epochs=epochs, criterion=criterion, optimizer=optimizer, scheduler=scheduler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert our models into graphs and then save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our model to graph\n",
    "\n",
    "from gmn.graph_models import *\n",
    "from torch_geometric.data import Data, Batch\n",
    "from gmn.graph_construct.model_arch_graph import sequential_to_arch, arch_to_graph, graph_to_arch, arch_to_sequential\n",
    "from gmn.feature_extractor_gmn import NodeEdgeFeatEncoder\n",
    "from gmn.graph_models import MPNN\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "gmn_dataset = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "\n",
    "    weights = torch.load(\"checkpoint/gmn_dataset/trained_model_\"+str(i)+\".pth\", map_location=\"mps\")\n",
    "    model = create_model()\n",
    "    model.load_state_dict(weights)\n",
    "    arch = sequential_to_arch(model)\n",
    "    x, edge_index, edge_attr = arch_to_graph(arch)\n",
    "    x = x.float()\n",
    "    edge_attr = edge_attr.float()\n",
    "\n",
    "    # currently u is a vector of zeros, and it is basically useless. You can consider filling it with what you prefer and leverage it for the task of unlearning\n",
    "    g_cnn = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, u = torch.zeros(1, 8))\n",
    "\n",
    "    graph_batch = Batch.from_data_list([g_cnn])\n",
    "    print(graph_batch)\n",
    "\n",
    "    weights_gt = torch.load(\"checkpoint/gmn_dataset/forget/forget_model_\"+str(i)+\".pth\", map_location=\"mps\")\n",
    "    model_gt = create_model()\n",
    "    model_gt.load_state_dict(weights_gt)\n",
    "    arch_gt = sequential_to_arch(model_gt)\n",
    "    x_gt, edge_index_gt, edge_attr_gt = arch_to_graph(arch_gt)\n",
    "    x_gt = x_gt.float()\n",
    "    edge_attr_gt = edge_attr_gt.float()\n",
    "\n",
    "    g_cnn_gt = Data(x=x_gt, edge_index=edge_index_gt, edge_attr=edge_attr_gt, u = torch.zeros(1, 8))\n",
    "\n",
    "    graph_batch_gt = Batch.from_data_list([g_cnn_gt])\n",
    "\n",
    "    gmn_dataset.append((graph_batch, graph_batch_gt)) # store it\n",
    "\n",
    "train_size = int(0.8 * len(gmn_dataset))  # 80% training\n",
    "val_size = len(gmn_dataset) - train_size  # 20% validation\n",
    "\n",
    "train_dataset, val_dataset = random_split(gmn_dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMN creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphMetaNetwork(nn.Module):\n",
    "    '''\n",
    "    Wrapper class for the graph metanetwork\n",
    "    '''\n",
    "    def __init__(self, encoder, mpnn):\n",
    "        super(GraphMetaNetwork, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.mpnn = mpnn\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, u, batch = data.x, data.edge_index, data.edge_attr, data.u, data.batch\n",
    "        x, edge_attr = self.encoder(x, edge_attr)\n",
    "        x, edge_attr, u = self.mpnn(x, edge_index, edge_attr, u, batch)\n",
    "        return edge_attr\n",
    "\n",
    "# Define the encoder and MPNN\n",
    "pre_embedding_dim = 64\n",
    "global_in_dim = 8\n",
    "hidden_dim = 32\n",
    "node_out_dim = 3\n",
    "edge_out_dim = 1\n",
    "global_out_dim = 8\n",
    "num_gnn_layers = 4\n",
    "encoder = NodeEdgeFeatEncoder(hidden_dim=pre_embedding_dim)\n",
    "mpnn = MPNN(node_in_dim=pre_embedding_dim,\n",
    "            edge_in_dim=pre_embedding_dim,\n",
    "            global_in_dim = global_in_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            node_out_dim= node_out_dim,\n",
    "            edge_out_dim = edge_out_dim,\n",
    "            global_out_dim= global_out_dim,\n",
    "            num_layers=num_gnn_layers,\n",
    "            reduce='mean')\n",
    "\n",
    "# Create the metanetwork\n",
    "gmn = GraphMetaNetwork(encoder, mpnn)\n",
    "gmn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we have to define our model loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Add your code below\n",
    "'''\n",
    "import collections\n",
    "\n",
    "# TODO: capire cosa va dato in input alla funzione\n",
    "def return_to_model(weights, arch):\n",
    "    if isinstance(weights, collections.OrderedDict):\n",
    "        weights = torch.cat([v.flatten() for v in weights.values()])\n",
    "\n",
    "\n",
    "    arch_new = graph_to_arch(arch, weights)\n",
    "\n",
    "    layers = []\n",
    "\n",
    "    for layer_info in arch_new:\n",
    "        layer_type = layer_info[0]\n",
    "        if layer_type == nn.Linear:\n",
    "            out_features, in_features = layer_info[1].shape\n",
    "            layers.append(nn.Linear(in_features, out_features))\n",
    "        elif layer_type == nn.Conv2d:\n",
    "            out_channels, in_channels, kernel_height, kernel_width = layer_info[1].shape\n",
    "            layers.append(nn.Conv2d(in_channels, out_channels, (kernel_height, kernel_width)))\n",
    "        elif layer_type == nn.BatchNorm2d:\n",
    "            num_features = layer_info[1].shape[0]\n",
    "            layers.append(nn.BatchNorm2d(num_features))\n",
    "            \n",
    "\n",
    "    model = nn.Sequential(*layers)\n",
    "\n",
    "    model = arch_to_sequential(arch_new, model)\n",
    "    print(model)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss(output_model, ground_truth_model, inp):\n",
    "    out1 = output_model(inp)\n",
    "    out2 = ground_truth_model(inp)\n",
    "\n",
    "    model1 = return_to_model()\n",
    "    model2 = return_to_model()\n",
    "    \n",
    "    mse_loss = torch.nn.functional.mse_loss(out1, out2)\n",
    "\n",
    "    return mse_loss\n",
    "\n",
    "criterion = loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train our GMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "use_bn = True\n",
    "dropout = 0.1\n",
    "reduce = 'sum'\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "num_epochs = 20\n",
    "\n",
    "cnn_train_dataset = datasets.CIFAR10(root=\"data\", train=True, transform=cifar_transforms, download=True)  \n",
    "cnn_test_dataset = datasets.CIFAR10(root=\"data\", train=False, transform=cifar_transforms, download=True) \n",
    "random_index = 0\n",
    "\n",
    "# Placeholder for storing losses for each epoch\n",
    "losses = []\n",
    "losses_val = []\n",
    "\n",
    "# Training the model\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    ######### TRAINING ##########\n",
    "    gmn.train()\n",
    "    running_loss = 0  # To track loss for this epoch\n",
    "\n",
    "    # Using tqdm for the progress bar\n",
    "    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=True)\n",
    "\n",
    "    \n",
    "    for batch_idx, (data, targets) in loop:\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        random_index = random.randint(0, len(cnn_train_dataset)-1)\n",
    "        cnn_train_data = cnn_train_dataset[random_index].to(device=device)\n",
    "\n",
    "        # Forward pass\n",
    "        output_model = gmn(data)\n",
    "        loss = criterion(output_model, targets, cnn_train_data)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Update progress bar with loss and epoch information\n",
    "        loop.set_description(f\"\\033[34mEpoch [{epoch+1}/{num_epochs}]\\033[0m\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "\n",
    "    #scheduler \n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "    # Print loss for this epoch\n",
    "    tqdm.write(f\"\\033[34mEpoch [{epoch+1}/{num_epochs}]\\033[0m, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    ####### VALIDATION ########\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in val_loader:\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "\n",
    "            random_index = random.randint(0, len(cnn_test_dataset)-1)\n",
    "            cnn_test_data = cnn_test_dataset[random_index].to(device=device)\n",
    "\n",
    "            scores = model(data)\n",
    "            loss = criterion(scores, targets, cnn_test_data)\n",
    "            val_loss += loss.item()\n",
    "        # Calculate average loss for the epoch\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        losses_val.append(avg_val_loss)\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "        # if avg val_loss is better than the one before, save the model\n",
    "        if epoch == 0:\n",
    "            # create directory if not exist\n",
    "            os.makedirs(\"checkpoint\", exist_ok=True)\n",
    "            best_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), \"checkpoint/gmn_trained_model_\"+str(count)+\".pth\")\n",
    "        elif avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), \"checkpoint/gmn_trained_model\"+str(count)+\".pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to convert the output of the gmn back into a neural network model (i.e., an ```nn.Sequential``` object), please look into ```graph_to_arch``` and ```arch_to_sequential``` functions stored in ```Practice/gmn/graph_construct/model_arch_graph.py```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report\n",
    "\n",
    "IDEA: Our GMN model will use MPNN to update input model weights, the model will be passed as a graph.\n",
    "\n",
    "We defined 3 main steps:\n",
    "\n",
    "1) Creation of our GMN dataset\n",
    "\n",
    "2) Training of our GMN\n",
    "\n",
    "3) Evaluation of our GMN\n",
    "\n",
    "Now let's have a deeper look inside these 3 steps:\n",
    "\n",
    "1) To create our GMN dataset, we decided to use 128 small CNNs, created with the help of create_model() function defined in one of the previous sections. After the creation, we had to train them, so we decided to use CIFAR-10 dataset and train them with different random epochs to get different behaivours. We also decided to apply this randomness to the choosing of the Optimization algorithm. To get ground_truth of every CNN in our dataset then we applied unlearning by Fine-tuning as we saw in the previous sections. At the end we converted all the models we got into graphs.\n",
    "\n",
    "2) To perform training, one of the main actions to do is to define the loss function, the most important part of the training phase. The idea for the loss function is the following: we get a random sample from the CIFAR-10 dataset, after we got our \"unlearned\" model graph from the GMN, first of all we convert it into a model (same thing will be performed on the ground_truth graph), then we will pass our random sample into these 2 models, at the end the two outputs will be compared by the application of the MSE.\n",
    "\n",
    "3) After training, we got the following results:\n",
    "\n",
    "PENSIERI SUI RISULTATI....\n",
    "\n",
    "We are aware to the fact that this GMN is bound to the dataset used to \"train\" the CNNs dataset. Since with the ground_truth we decided to unlearn a certain class S, then our GMN will give as output models that unlearned class S. We can consider it as a first good step to get into this unlearning technique, surely it can be developed in a better way in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
